# ü§ñ Guia Completo de Comandos Ollama

## üì• **BAIXAR MODELOS**
```bash
ollama pull llama2                    # Baixa modelo do reposit√≥rio
ollama pull gemma:2b                  # Baixa vers√£o espec√≠fica
ollama pull codellama:13b-instruct    # Baixa modelo para c√≥digo
```

## üéØ **EXECUTAR MODELOS**
```bash
ollama run llama2                     # Inicia chat interativo
ollama run llama2 "Pergunta aqui"    # Pergunta √∫nica
ollama run sofiaai-personal           # Roda seu modelo personalizado
```

## üìù **CRIAR MODELOS PERSONALIZADOS**
```bash
ollama create meu-modelo -f Modelfile       # Cria modelo do Modelfile
ollama create nome-modelo -f arquivo.txt    # Cria de arquivo espec√≠fico
```

## üìã **LISTAR E GERENCIAR**
```bash
ollama list                           # Lista todos os modelos
ollama ls                            # Mesmo que list (abreviado)
ollama show llama2                   # Mostra detalhes do modelo
ollama show llama2 --modelfile       # Mostra o Modelfile usado
```

## üóëÔ∏è **DELETAR MODELOS**
```bash
ollama rm llama2                     # Remove modelo espec√≠fico
ollama rm llama2:13b                 # Remove vers√£o espec√≠fica
ollama rm sofiaai:latest             # Remove por tag
```

## üíæ **COPIAR E RENOMEAR**
```bash
ollama cp llama2 minha-llama         # Copia/renomeia modelo
ollama cp sofiaai-personal backup    # Faz backup do modelo
```

## üîß **SERVIDOR E SERVI√áOS**
```bash
ollama serve                         # Inicia servidor Ollama
ollama ps                           # Lista modelos em execu√ß√£o
```

## üåê **API E INTEGRA√á√ÉO**
```bash
# Usar via API REST
curl http://localhost:11434/api/generate -d '{
  "model": "sofiaai-personal",
  "prompt": "Ol√°!"
}'
```

## üìä **INFORMA√á√ïES DO SISTEMA**
```bash
ollama version                       # Mostra vers√£o do Ollama
ollama --help                      # Ajuda geral
ollama run --help                  # Ajuda para comando espec√≠fico
```

## ‚öôÔ∏è **PAR√ÇMETROS AVAN√áADOS**
```bash
# Executar com par√¢metros personalizados
ollama run llama2 --temperature 0.8 "Pergunta"
ollama run llama2 --num-predict 100 "Pergunta"
ollama run llama2 --top-p 0.9 "Pergunta"
```

## üöÄ **DICAS √öTEIS**

### **Listar modelos por tamanho:**
```bash
ollama list | sort -k3 -h           # Ordena por tamanho
```

### **Verificar espa√ßo usado:**
```bash
ollama list | awk '{sum+=$3} END {print "Total:", sum "GB"}'
```

### **Executar em modo n√£o-interativo:**
```bash
echo "Sua pergunta" | ollama run sofiaai-personal
```

### **Salvar resposta em arquivo:**
```bash
ollama run llama2 "Explique IA" > resposta.txt
```

## üìÇ **LOCALIZA√á√ÉO DOS ARQUIVOS**
- **Windows:** `C:\Users\%USERNAME%\.ollama\models`
- **Linux/Mac:** `~/.ollama/models`

## üî• **COMANDOS MAIS USADOS NO DIA A DIA**
```bash
ollama list                          # Ver seus modelos
ollama run sofiaai-personal          # Usar sua SofiaAI
ollama rm modelo-antigo              # Limpar espa√ßo
ollama pull novo-modelo              # Baixar modelo novo
ollama create backup -f Modelfile    # Fazer backup personalizado
```

## ‚ö° **ATALHOS R√ÅPIDOS**
- `Ctrl+C` - Sair do chat
- `Ctrl+D` - Sair do modelo  
- `/bye` - Sair (em alguns modelos)
- `/clear` - Limpar conversa

## üéØ **EXEMPLOS PR√ÅTICOS PARA SOFIAAI**
```bash
# Testar a SofiaAI
ollama run sofiaai-personal "Quem te criou?"

# Fazer backup
ollama cp sofiaai-personal sofiaai-backup

# Ver detalhes
ollama show sofiaai-personal

# Usar para c√≥digo
ollama run sofiaai-personal "Como fazer um loop em Python?"
```